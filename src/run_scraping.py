"""
Script unificado para scraping de datos de FEB.

Este script permite:
- Scraping incremental (solo encuentros nuevos)
- Scraping completo (re-scraping)
- Scraping de m√∫ltiples competiciones
- Consultar estado y base de datos
"""

from .main import FEBScoutingScraper
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def list_competitions():
    """Listar todas las competiciones disponibles."""
    print("\n" + "="*60)
    print("LISTAR COMPETICIONES DISPONIBLES")
    print("="*60 + "\n")
    
    scraper = FEBScoutingScraper()
    competitions = scraper.list_available_competitions()
    print(f"\nTotal competitions found: {len(competitions)}")
    scraper.close()


def scrape_interactive():
    """Scraping interactivo - permite elegir competici√≥n."""
    print("\n" + "="*60)
    print("SCRAPING INTERACTIVO (INCREMENTAL)")
    print("="*60 + "\n")
    
    scraper = FEBScoutingScraper()
    
    # Listar competiciones disponibles
    print("Competiciones disponibles:")
    print("-"*60)
    competitions = scraper.list_available_competitions()
    
    if not competitions:
        print("No se encontraron competiciones. Verifica la conexi√≥n.")
        scraper.close()
        return
    
    # Solicitar nombre de competici√≥n
    print("\n" + "="*60)
    comp_name = input("Introduce el nombre de la competici√≥n (ej: 'LF2', 'LEB ORO'): ").strip()
    
    if not comp_name:
        print("No se proporcion√≥ nombre. Cancelando.")
        scraper.close()
        return
    
    # Scraping incremental (por defecto)
    print(f"\nüîÑ Scraping incremental de: {comp_name}")
    print("Solo se procesar√°n encuentros nuevos que no est√©n en la BD")
    print("-"*60)
    
    stats = scraper.scrape_competition_by_name(comp_name, incremental=True)
    
    print("\n" + "="*60)
    print("üìä RESULTADOS:")
    print("="*60)
    print(f"Competici√≥n: {stats.get('competition', 'N/A')}")
    print(f"G√©nero: {stats.get('gender', 'N/A')}")
    print(f"Colecci√≥n: {stats.get('collection', 'N/A')}")
    print(f"Temporadas: {stats.get('total_seasons', 0)}")
    print(f"Grupos: {stats.get('total_groups', 0)}")
    print(f"Encuentros encontrados: {stats.get('total_matches_found', 0)}")
    print(f"‚úÖ Encuentros nuevos procesados: {stats.get('total_matches_scraped', 0)}")
    print(f"‚è≠Ô∏è  Encuentros omitidos (ya en BD): {stats.get('total_matches_skipped', 0)}")
    print(f"‚ùå Encuentros fallidos: {stats.get('total_matches_failed', 0)}")
    
    scraper.close()


def scrape_full_rescrape():
    """Scraping completo (re-scraping) - procesa todos los encuentros."""
    print("\n" + "="*60)
    print("SCRAPING COMPLETO (RE-SCRAPING)")
    print("="*60 + "\n")
    
    scraper = FEBScoutingScraper()
    
    # Listar competiciones
    print("Competiciones disponibles:")
    print("-"*60)
    scraper.list_available_competitions()
    
    # Solicitar nombre
    print("\n" + "="*60)
    comp_name = input("Introduce el nombre de la competici√≥n: ").strip()
    
    if not comp_name:
        print("No se proporcion√≥ nombre. Cancelando.")
        scraper.close()
        return
    
    # Confirmar operaci√≥n
    confirm = input(f"\n‚ö†Ô∏è  ¬øConfirmas re-scraping COMPLETO de '{comp_name}'? (s/n): ").strip().lower()
    
    if confirm not in ['s', 'si', 's√≠', 'y', 'yes']:
        print("Operaci√≥n cancelada.")
        scraper.close()
        return
    
    # Scraping completo
    print(f"\nüîÑ Re-scraping completo de: {comp_name}")
    print("Se procesar√°n TODOS los encuentros, incluso los existentes")
    print("-"*60)
    
    stats = scraper.scrape_competition_by_name(comp_name, incremental=False)
    
    print("\n" + "="*60)
    print("üìä RESULTADOS:")
    print("="*60)
    print(f"Encuentros encontrados: {stats.get('total_matches_found', 0)}")
    print(f"Encuentros procesados: {stats.get('total_matches_scraped', 0)}")
    print(f"Encuentros fallidos: {stats.get('total_matches_failed', 0)}")
    
    scraper.close()


def scrape_multiple_competitions():
    """Scraping de m√∫ltiples competiciones."""
    print("\n" + "="*60)
    print("SCRAPING M√öLTIPLES COMPETICIONES")
    print("="*60 + "\n")
    
    scraper = FEBScoutingScraper()
    
    # Solicitar competiciones
    print("Introduce las competiciones separadas por comas")
    print("Ejemplo: LF2, LF, LEB ORO, ACB")
    comp_input = input("\nCompeticiones: ").strip()
    
    if not comp_input:
        print("No se proporcionaron competiciones. Cancelando.")
        scraper.close()
        return
    
    competiciones = [c.strip() for c in comp_input.split(',')]
    
    print(f"\nüîÑ Procesando {len(competiciones)} competiciones...")
    print("-"*60)
    
    resultados = {}
    
    for comp in competiciones:
        print(f"\nüì• Procesando: {comp}")
        stats = scraper.scrape_competition_by_name(comp, incremental=True)
        resultados[comp] = stats
        
        print(f"  ‚úÖ {stats.get('total_matches_scraped', 0)} nuevos, "
              f"‚è≠Ô∏è  {stats.get('total_matches_skipped', 0)} omitidos")
    
    # Resumen final
    print("\n" + "="*60)
    print("üìä RESUMEN FINAL:")
    print("="*60)
    total_nuevos = sum(r.get('total_matches_scraped', 0) for r in resultados.values())
    total_omitidos = sum(r.get('total_matches_skipped', 0) for r in resultados.values())
    total_fallidos = sum(r.get('total_matches_failed', 0) for r in resultados.values())
    
    print(f"Total encuentros nuevos: {total_nuevos}")
    print(f"Total encuentros omitidos: {total_omitidos}")
    print(f"Total encuentros fallidos: {total_fallidos}")
    
    scraper.close()


def query_database():
    """Consultar estado de la base de datos."""
    print("\n" + "="*60)
    print("CONSULTAR BASE DE DATOS")
    print("="*60 + "\n")
    
    scraper = FEBScoutingScraper()
    
    # Contar partidos
    masc_count = scraper.db_client.count_games("all_feb_games_masc")
    fem_count = scraper.db_client.count_games("all_feb_games_fem")
    
    print(f"üèÄ Partidos masculinos: {masc_count}")
    print(f"üèÄ Partidos femeninos: {fem_count}")
    print(f"üìä Total partidos: {masc_count + fem_count}")
    
    # Muestra de partido
    if fem_count > 0 or masc_count > 0:
        print("\n" + "-"*60)
        print("MUESTRA DE PARTIDO:")
        print("-"*60)
        
        collection = "all_feb_games_fem" if fem_count > 0 else "all_feb_games_masc"
        games = scraper.db_client.get_all_games(collection)
        
        if games:
            sample = games[0]
            header = sample.get("HEADER", {})
            print(f"Competici√≥n: {header.get('competition_name', 'N/A')}")
            print(f"Temporada: {header.get('season', 'N/A')}")
            print(f"Grupo: {header.get('group', 'N/A')}")
            print(f"Fecha: {header.get('starttime', 'N/A')}")
            
            teams = header.get("TEAM", [])
            if len(teams) == 2:
                print(f"\nPartido: {teams[0].get('name', 'N/A')} {teams[0].get('pts', '?')} - "
                      f"{teams[1].get('pts', '?')} {teams[1].get('name', 'N/A')}")
    
    scraper.close()


def view_scraping_state():
    """Ver el estado actual del scraping incremental."""
    print("\n" + "="*60)
    print("ESTADO DEL SCRAPING INCREMENTAL")
    print("="*60 + "\n")
    
    from .database import MongoDBClient
    
    db = MongoDBClient()
    
    try:
        state_collection = db.get_collection("scraping_state")
        states = list(state_collection.find().sort("last_update", -1))
        
        if not states:
            print("‚ÑπÔ∏è  No hay estados de scraping guardados.")
            print("El estado se crea autom√°ticamente al hacer scraping incremental.")
            return
        
        print(f"{'Competici√≥n':<20} {'Temporada':<15} {'Grupo':<30} {'Partidos':<10} {'√öltima Act.'}")
        print("-" * 110)
        
        for state in states:
            comp = state.get('competition_name', 'N/A')[:19]
            season = state.get('season', 'N/A')[:14]
            group = state.get('group', 'N/A')[:29]
            total = state.get('total_matches', 0)
            update = state.get('last_update', 'N/A')[:19]
            
            print(f"{comp:<20} {season:<15} {group:<30} {total:<10} {update}")
        
        print(f"\nTotal grupos procesados: {len(states)}")
        
    finally:
        db.close()


def reset_scraping_state():
    """Resetear el estado del scraping incremental."""
    print("\n" + "="*60)
    print("RESETEAR ESTADO DEL SCRAPING")
    print("="*60 + "\n")
    
    from database import MongoDBClient
    
    db = MongoDBClient()
    
    try:
        state_collection = db.get_collection("scraping_state")
        
        print("Opciones:")
        print("1. Resetear una competici√≥n espec√≠fica")
        print("2. Resetear TODO el estado")
        print("0. Cancelar")
        
        opcion = input("\nSelecciona opci√≥n: ").strip()
        
        if opcion == "1":
            comp_name = input("Nombre de la competici√≥n: ").strip()
            if comp_name:
                result = state_collection.delete_many({"competition_name": comp_name})
                print(f"\n‚úÖ Estado reseteado para '{comp_name}': "
                      f"{result.deleted_count} documentos eliminados")
            else:
                print("‚ùå No se proporcion√≥ nombre.")
        
        elif opcion == "2":
            confirm = input("\n‚ö†Ô∏è  ¬øConfirmas resetear TODO el estado? (s/n): ").strip().lower()
            if confirm in ['s', 'si', 's√≠', 'y', 'yes']:
                result = state_collection.delete_many({})
                print(f"\n‚úÖ Todo el estado reseteado: "
                      f"{result.deleted_count} documentos eliminados")
            else:
                print("‚ùå Operaci√≥n cancelada")
        
        elif opcion == "0":
            print("Operaci√≥n cancelada.")
        
        else:
            print("‚ùå Opci√≥n no v√°lida")
        
    finally:
        db.close()


def custom_database():
    """Usar configuraci√≥n personalizada de MongoDB."""
    print("\n" + "="*60)
    print("CONFIGURACI√ìN PERSONALIZADA DE MONGODB")
    print("="*60 + "\n")
    
    print("Configuraci√≥n por defecto:")
    print("  URI: mongodb://localhost:27017/")
    print("  Database: scouting_feb")
    print()
    
    uri = input("URI de MongoDB (Enter para usar por defecto): ").strip()
    db_name = input("Nombre de base de datos (Enter para usar por defecto): ").strip()
    
    if not uri:
        uri = "mongodb://localhost:27017/"
    if not db_name:
        db_name = "scouting_feb"
    
    print(f"\nüì° Conectando a: {uri}")
    print(f"üìä Base de datos: {db_name}")
    
    scraper = FEBScoutingScraper(
        mongodb_uri=uri,
        database_name=db_name
    )
    
    competitions = scraper.list_available_competitions()
    print(f"\n‚úÖ Conectado exitosamente")
    print(f"Competiciones encontradas: {len(competitions)}")
    
    scraper.close()


def main():
    """Funci√≥n principal con men√∫ interactivo."""
    
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë            ScoutingFEB - Sistema de Scraping                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

Selecciona una opci√≥n:

[SCRAPING]
  1. Listar competiciones disponibles
  2. Scraping interactivo (incremental)
  3. Scraping completo (re-scraping)
  4. M√∫ltiples competiciones

[CONSULTAS]
  5. Consultar base de datos
  6. Ver estado del scraping incremental
  
[ADMINISTRACI√ìN]
  7. Resetear estado del scraping
  8. Configuraci√≥n personalizada de MongoDB

  0. Salir
""")
    
    opcion = input("Opci√≥n: ").strip()
    
    opciones = {
        "1": list_competitions,
        "2": scrape_interactive,
        "3": scrape_full_rescrape,
        "4": scrape_multiple_competitions,
        "5": query_database,
        "6": view_scraping_state,
        "7": reset_scraping_state,
        "8": custom_database
    }
    
    if opcion in opciones:
        try:
            opciones[opcion]()
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  Operaci√≥n interrumpida por el usuario")
        except Exception as e:
            logger.error(f"‚ùå Error: {e}", exc_info=True)
    elif opcion == "0":
        print("\n¬°Hasta luego! üëã")
    else:
        print("\n‚ùå Opci√≥n no v√°lida")


if __name__ == "__main__":
    main()
