# ScoutingFEB

Sistema de scouting de baloncesto basado en IA para predecir el rendimiento futuro de jugadores usando datos estadÃ­sticos de la FederaciÃ³n EspaÃ±ola de Baloncesto (FEB).

## ðŸŽ¯ CaracterÃ­sticas Principales

- **Scraping AutomÃ¡tico**: RecopilaciÃ³n de datos de partidos desde la web de la FEB
- **Sistema Incremental**: Solo procesa encuentros nuevos (ahorro 97-98%)
- **ETL Completo**: Pipeline de transformaciÃ³n MongoDB â†’ SQLite
- **Machine Learning**: Modelos XGBoost para predicciÃ³n de rendimiento
- **Interpretabilidad**: Explicaciones SHAP de las predicciones
- **Base de Datos Dual**: MongoDB (raw) + SQLite (procesado)

## DescripciÃ³n

ScoutingFEB es un proyecto que combina web scraping, anÃ¡lisis de datos y inteligencia artificial para ayudar en el proceso de scouting de jugadores de baloncesto. El sistema recopila datos detallados de partidos de la FEB y los almacena en una base de datos MongoDB para su posterior anÃ¡lisis.

## CaracterÃ­sticas

- âœ… **Scraping automÃ¡tico de datos FEB**: Obtiene todos los partidos de competiciones FEB
- âœ… **Sistema incremental**: Solo procesa encuentros nuevos, ahorrando tiempo y recursos
- âœ… **MÃºltiples temporadas y grupos**: Recopila datos histÃ³ricos completos
- âœ… **SeparaciÃ³n por gÃ©nero**: Almacenamiento separado para competiciones masculinas y femeninas
- âœ… **Base de datos MongoDB**: Almacenamiento eficiente y escalable
- âœ… **Datos detallados**: Incluye estadÃ­sticas de jugadores, play-by-play, y shot charts
- âœ… **Sistema de logging**: Seguimiento completo del proceso de scraping

## Estructura del Proyecto

```
ScoutingFEB/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                         # Scraper principal
â”‚   â”œâ”€â”€ config.py                       # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ utils.py                        # Utilidades
â”‚   â”œâ”€â”€ examples.py                     # Ejemplos de uso
â”‚   â”œâ”€â”€ examples_incremental.py         # Ejemplos sistema incremental
â”‚   â”œâ”€â”€ test_incremental.py             # Tests
â”‚   â”œâ”€â”€ run_ml_pipeline.py              # ðŸ†• Pipeline completo ML
â”‚   â”‚
â”‚   â”œâ”€â”€ scraper/                        # MÃ³dulo de scraping
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ api_client.py
â”‚   â”‚   â”œâ”€â”€ constants.py
â”‚   â”‚   â”œâ”€â”€ data_processor.py
â”‚   â”‚   â”œâ”€â”€ feb_scraper.py
â”‚   â”‚   â”œâ”€â”€ token_manager.py
â”‚   â”‚   â””â”€â”€ web_client.py
â”‚   â”‚
â”‚   â”œâ”€â”€ database/                       # MÃ³dulo de bases de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ mongodb_client.py          # Cliente MongoDB
â”‚   â”‚   â””â”€â”€ sqlite_schema.py           # ðŸ†• Esquema SQLite
â”‚   â”‚
â”‚   â””â”€â”€ ml/                             # ðŸ†• MÃ³dulo de Machine Learning
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ etl_processor.py           # ETL MongoDB â†’ SQLite
â”‚       â””â”€â”€ xgboost_model.py           # Modelos XGBoost + SHAP
â”‚
â”œâ”€â”€ models/                             # ðŸ†• Modelos ML entrenados
â”‚   â”œâ”€â”€ *.joblib                       # Modelos serializados
â”‚   â”œâ”€â”€ *_metadata.json                # Metadata
â”‚   â””â”€â”€ *_shap_summary.png             # GrÃ¡ficos SHAP
â”‚
â”œâ”€â”€ requirements.txt                    # Dependencias
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ QUICKSTART.md                      # GuÃ­a rÃ¡pida
â”œâ”€â”€ CHANGELOG.md                       # Historial de cambios
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ INCREMENTAL_SCRAPING.md            # ðŸ“š Doc: Sistema incremental
â”œâ”€â”€ INCREMENTAL_SYSTEM_DIAGRAM.md      # ðŸ“š Doc: Diagramas
â”œâ”€â”€ ML_SYSTEM.md                       # ðŸ“š Doc: Sistema ML
â””â”€â”€ ARCHITECTURE.md                    # ðŸ“š Doc: Arquitectura completa
```

## Requisitos

### Software Necesario
- Python 3.8 o superior
- MongoDB 4.0 o superior (para datos raw)
- SQLite 3 (incluido con Python)
- ConexiÃ³n a Internet para scraping

### LibrerÃ­as Python
Ver `requirements.txt` para la lista completa. Principales:
- **Scraping**: requests, beautifulsoup4, pymongo
- **ML**: xgboost, shap, scikit-learn, pandas, numpy
- **VisualizaciÃ³n**: matplotlib

## InstalaciÃ³n

1. **Clonar o descargar el repositorio**

2. **Instalar MongoDB** (si no lo tienes instalado)
   
   Windows:
   ```powershell
   # Descargar desde: https://www.mongodb.com/try/download/community
   # O usar Chocolatey:
   choco install mongodb
   ```

   AsegÃºrate de que MongoDB estÃ© ejecutÃ¡ndose:
   ```powershell
   # Iniciar MongoDB como servicio
   net start MongoDB
   ```

3. **Instalar dependencias de Python**
   ```powershell
   cd ScoutingFEB
   pip install -r requirements.txt
   ```

## ðŸš€ Inicio RÃ¡pido

### OpciÃ³n 1: Solo Scraping

```powershell
# 1. Asegurarte de que MongoDB estÃ© ejecutÃ¡ndose
net start MongoDB

# 2. Ejecutar scraper
cd src
python main.py
```

### OpciÃ³n 2: Pipeline Completo (Scraping + ETL + ML)

```powershell
# Ejecutar pipeline completo
cd src
python run_ml_pipeline.py

# Opciones avanzadas:
python run_ml_pipeline.py --limit 100      # Prueba con 100 partidos
python run_ml_pipeline.py --skip-etl       # Saltar ETL (usar datos existentes)
python run_ml_pipeline.py --skip-training  # Saltar entrenamiento
```

Este comando ejecutarÃ¡:
1. âœ… CreaciÃ³n de esquema SQLite
2. âœ… Proceso ETL (MongoDB â†’ SQLite)
3. âœ… Entrenamiento de modelos XGBoost
4. âœ… AnÃ¡lisis SHAP de interpretabilidad
5. âœ… Predicciones de ejemplo

## ðŸ“š DocumentaciÃ³n

### GuÃ­as Principales
- **[QUICKSTART.md](QUICKSTART.md)** - GuÃ­a rÃ¡pida de inicio
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - Arquitectura completa del sistema
- **[ML_SYSTEM.md](ML_SYSTEM.md)** - Sistema de Machine Learning con XGBoost + SHAP
- **[INCREMENTAL_SCRAPING.md](INCREMENTAL_SCRAPING.md)** - Sistema de scraping incremental

### Diagramas y Ejemplos
- **[INCREMENTAL_SYSTEM_DIAGRAM.md](INCREMENTAL_SYSTEM_DIAGRAM.md)** - Diagramas del sistema incremental
- **[CHANGELOG.md](CHANGELOG.md)** - Historial de cambios y versiones

## Uso

### Sistema de Scraping Incremental

ScoutingFEB incluye un **sistema de scraping incremental** que reduce significativamente el costo de la recopilaciÃ³n de datos al procesar solo los encuentros nuevos.

ðŸ“– **[Ver documentaciÃ³n completa del sistema incremental](INCREMENTAL_SCRAPING.md)**

**Uso rÃ¡pido:**
```python
from src.main import FEBScoutingScraper

scraper = FEBScoutingScraper()

# Modo incremental (por defecto) - solo procesa encuentros nuevos
stats = scraper.scrape_competition_by_name("LF2", incremental=True)

# Modo completo - procesa todos los encuentros
stats = scraper.scrape_competition_by_name("LF2", incremental=False)

scraper.close()
```

**Ejemplos interactivos:**
```powershell
python src/examples_incremental.py
```

### 1. Listar competiciones disponibles

Para ver todas las competiciones FEB disponibles:

```powershell
cd src
python main.py
```

Esto mostrarÃ¡ una lista de todas las competiciones con su gÃ©nero detectado automÃ¡ticamente.

### 2. Scraping de una competiciÃ³n especÃ­fica

Edita el archivo `main.py` y descomenta las lÃ­neas relevantes en la funciÃ³n `main()`:

**OpciÃ³n A: Por nombre de competiciÃ³n**
```python
# Busca automÃ¡ticamente la competiciÃ³n por nombre
scraper.scrape_competition_by_name("LF2")
```

**OpciÃ³n B: Por URL directa**
```python
stats = scraper.scrape_competition(
    "https://baloncestoenvivo.feb.es/calendario/lf2/9/2024",
    "LF2 - Liga Femenina 2",
    "fem"  # 'masc' o 'fem'
)
```

Luego ejecuta:
```powershell
python main.py
```

### 3. Uso programÃ¡tico

TambiÃ©n puedes usar el scraper en tu propio cÃ³digo:

```python
from main import FEBScoutingScraper

# Inicializar el scraper
scraper = FEBScoutingScraper(
    mongodb_uri="mongodb://localhost:27017/",
    database_name="scouting_feb"
)

# Listar competiciones
competitions = scraper.list_available_competitions()

# Scraping de una competiciÃ³n
stats = scraper.scrape_competition_by_name("LF2")

# Cerrar conexiones
scraper.close()
```

## Colecciones de MongoDB

Los datos se almacenan en mÃºltiples colecciones:

### Colecciones de Partidos
- **all_feb_games_masc**: Partidos de competiciones masculinas
- **all_feb_games_fem**: Partidos de competiciones femeninas

### ColecciÃ³n de Estado (Sistema Incremental)
- **scraping_state**: Guarda el estado del scraping por competiciÃ³n/temporada/grupo para el procesamiento incremental

Cada documento de partido contiene:
- **HEADER**: InformaciÃ³n del partido (equipos, resultado, fecha, lugar)
- **BOXSCORE**: EstadÃ­sticas detalladas de jugadores
- **PLAYBYPLAY**: Jugada a jugada del partido
- **SHOTCHART**: InformaciÃ³n de todos los tiros
- Metadatos adicionales (competiciÃ³n, temporada, grupo, gÃ©nero)

## ConfiguraciÃ³n

### Cambiar la base de datos MongoDB

Por defecto, el sistema usa:
- URI: `mongodb://localhost:27017/`
- Base de datos: `scouting_feb`

Para cambiar esto, modifica los parÃ¡metros al inicializar `FEBScoutingScraper`:

```python
scraper = FEBScoutingScraper(
    mongodb_uri="mongodb://tu-servidor:27017/",
    database_name="tu_base_de_datos"
)
```

### Configurar logging

El sistema genera logs en:
- Consola (stdout)
- Archivo: `scouting_feb.log`

Puedes modificar el nivel de logging en `main.py`:

```python
logging.basicConfig(
    level=logging.DEBUG,  # Cambia a DEBUG para mÃ¡s detalle
    # ...
)
```

## CaracterÃ­sticas del Scraping

- **AutomÃ¡tico**: Detecta automÃ¡ticamente todas las temporadas y grupos disponibles
- **Incremental**: Solo procesa encuentros nuevos (sistema de estado con MongoDB)
- **Configurable**: Puede forzarse un re-scraping completo si es necesario
- **Resiliente**: Maneja errores y continÃºa con el siguiente partido
- **Respetuoso**: Incluye delays entre peticiones (0.5 segundos)
- **Completo**: Obtiene boxscore, play-by-play y shot charts
- **Trazable**: Guarda el estado de cada scraping con timestamps

## Ejemplo de Salida

```
=== Available FEB Competitions ===

- LF2 - Liga Femenina 2 (fem) - https://...
- LEB ORO - Liga Masculina (masc) - https://...
...

=== Starting scraping process ===

2025-01-12 10:30:00 - INFO - Starting scrape for LF2 (fem)
2025-01-12 10:30:00 - INFO - Found 5 seasons
2025-01-12 10:30:01 - INFO - Processing season: 2024/25
2025-01-12 10:30:02 - INFO - Found 4 groups in season 2024/25
2025-01-12 10:30:03 - INFO - Found 132 matches in 2024/25 - Grupo A
...
```

## PrÃ³ximos Pasos

Este proyecto estÃ¡ diseÃ±ado para ser la base de un sistema de scouting mÃ¡s completo. Los siguientes pasos incluirÃ­an:

1. **AnÃ¡lisis estadÃ­stico**: Procesamiento de datos para extraer mÃ©tricas avanzadas
2. **Modelos de IA**: PredicciÃ³n de rendimiento futuro de jugadores
3. **API REST**: ExposiciÃ³n de datos y predicciones
4. **Dashboard web**: VisualizaciÃ³n de datos y anÃ¡lisis
5. **Sistema de alertas**: Notificaciones sobre jugadores prometedores

## SoluciÃ³n de Problemas

### MongoDB no se conecta

Verifica que MongoDB estÃ© ejecutÃ¡ndose:
```powershell
# Windows
net start MongoDB

# O comprueba el estado
sc query MongoDB
```

### Errores de scraping

- Verifica tu conexiÃ³n a Internet
- La web de la FEB puede estar temporalmente no disponible
- Revisa el archivo `scouting_feb.log` para mÃ¡s detalles

### Dependencias faltantes

```powershell
pip install -r requirements.txt --upgrade
```

## Licencia

Este proyecto es de cÃ³digo abierto para fines educativos y de investigaciÃ³n.

## Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue o pull request.

## Contacto

Para preguntas o sugerencias, abre un issue en el repositorio.

---

**Nota**: Este proyecto no estÃ¡ afiliado con la FederaciÃ³n EspaÃ±ola de Baloncesto. Los datos se obtienen de fuentes pÃºblicas para fines de anÃ¡lisis deportivo.
